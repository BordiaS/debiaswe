{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on Tutorial: Quantifying and Reducing Gender Stereotypes in Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuring fairness in algorithmically-driven decision-making is important to avoid inadvertent cases of bias and perpetuation of harmful stereotypes. However, modern natural language processing techniques, which learn model parameters based on data, might rely on implicit biases presented in the data to make undesirable stereotypical associations. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. Recent results ([1](https://arxiv.org/abs/1607.06520), [2](https://arxiv.org/abs/1608.07187)) show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because of their widespread use, as we describe, often tends to amplify these biases. In the following, we provide step-by-step instructions to demonstrate and quanitfy the biases in word embedding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup:\n",
    "#\n",
    "# Download embeddings at https://github.com/tolga-b/debiaswe\n",
    "# embeddings/GoogleNews-vectors-negative300-hard-debiased.bin\n",
    "# embeddings/GoogleNews-vectors-negative300.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import debiaswe as dwe\n",
    "from debiaswe.we import WordEmbedding\n",
    "from debiaswe.data import load_professions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load data\n",
    "We first load the word embedding trained on a corpus of Google News texts consisting of 3 million English words and terms. The embedding maps each word into a 300-dimension vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load google news word2vec\n",
    "E_gnews = WordEmbedding(\"./embeddings/GoogleNews-vectors-negative300.bin\")\n",
    "\n",
    "# load professions\n",
    "professions = load_professions()\n",
    "profession_words = [p[0] for p in professions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: define gender direction\n",
    "\n",
    "We define gender direction by the direciton of she - he because they are frequent and do not have fewer alternative word senses (e.g., man can also refer to mankind)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gender direction\n",
    "v_gender = E_gnews.diff('she', 'he')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Generating analogies of \"Man: x :: Woman : y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Reading data from w2v_paper.txt\n",
      "(26379, 300)\n",
      "(26379, 'words of dimension', 300, ':', u'in, for, that, is, ..., indelible, electricians, flag_icon_below, foolishly')\n",
      "Computing neighbors\n",
      "('Mean:', 10.219492778346412)\n",
      "('Median:', 7.0)\n",
      "she-he\n",
      "herself-himself\n",
      "her-his\n",
      "woman-man\n",
      "daughter-son\n",
      "businesswoman-businessman\n",
      "girl-boy\n",
      "actress-actor\n",
      "chairwoman-chairman\n",
      "heroine-hero\n",
      "mother-father\n",
      "spokeswoman-spokesman\n",
      "sister-brother\n",
      "girls-boys\n",
      "sisters-brothers\n",
      "queen-king\n",
      "niece-nephew\n",
      "councilwoman-councilman\n",
      "motherhood-fatherhood\n",
      "women-men\n",
      "petite-lanky\n",
      "ovarian_cancer-prostate_cancer\n",
      "schoolgirl-schoolboy\n",
      "granddaughter-grandson\n",
      "aunt-uncle\n",
      "matriarch-patriarch\n",
      "twin_sister-twin_brother\n",
      "mom-dad\n",
      "Mary-John\n",
      "lesbian-gay\n",
      "husband-younger_brother\n",
      "gal-dude\n",
      "lady-gentleman\n",
      "sorority-fraternity\n",
      "mothers-fathers\n",
      "grandmother-grandfather\n",
      "blouse-shirt\n",
      "soprano-baritone\n",
      "queens-kings\n",
      "daughters-sons\n",
      "grandma-grandpa\n",
      "volleyball-football\n",
      "diva-superstar\n",
      "mommy-kid\n",
      "hairdresser-barber\n",
      "softball-baseball\n",
      "goddess-god\n",
      "waitress-waiter\n",
      "princess-prince\n",
      "filly-colt\n",
      "mare-gelding\n",
      "ladies-gentlemen\n",
      "childhood-boyhood\n",
      "interior_designer-architect\n",
      "nun-priest\n",
      "wig-beard\n",
      "granddaughters-grandsons\n",
      "girlfriends-buddies\n",
      "gals-dudes\n",
      "aunts-uncles\n",
      "congresswoman-congressman\n",
      "feminism-conservatism\n",
      "bitch-bastard\n",
      "hers-yours\n",
      "bra-pants\n",
      "moms-dads\n",
      "nurse-surgeon\n",
      "heiress-magnate\n",
      "feminine-manly\n",
      "glamorous-flashy\n",
      "actresses-actors\n",
      "registered_nurse-physician\n",
      "cupcakes-pizzas\n",
      "blond-burly\n",
      "babe-fella\n",
      "mums-blokes\n",
      "gorgeous-magnificent\n",
      "compatriot-countryman\n",
      "fabulous-terrific\n",
      "breast-prostate\n",
      "starlet-youngster\n",
      "kids-guys\n",
      "sewing-carpentry\n",
      "kinda-guy\n",
      "headscarf-turban\n",
      "siblings-elder_brother\n",
      "charming-affable\n",
      "sassy-snappy\n",
      "cosmetics-pharmaceuticals\n",
      "estrogen-testosterone\n",
      "handbag-briefcase\n",
      "housewife-shopkeeper\n",
      "fillies-colts\n",
      "nieces-nephews\n",
      "whore-coward\n",
      "boyfriend-pal\n",
      "salon-barbershop\n",
      "vagina-penis\n",
      "breast_cancer-lymphoma\n",
      "vocalist-guitarist\n"
     ]
    }
   ],
   "source": [
    "# analogies gender\n",
    "E = WordEmbedding('./embeddings/w2v_paper.txt')\n",
    "\n",
    "a_gender = E.best_analogies_dist_thresh(v_gender)\n",
    "\n",
    "for (a,b,c) in a_gender:\n",
    "    print(a+\"-\"+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Analyzing gender bias in word vectors asscoiated with professions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(-0.23798445, u'maestro'),\n",
       "  (-0.21665449, u'statesman'),\n",
       "  (-0.2075869, u'skipper'),\n",
       "  (-0.20267184, u'protege'),\n",
       "  (-0.20206775, u'businessman'),\n",
       "  (-0.1949237, u'sportsman'),\n",
       "  (-0.18836346, u'philosopher'),\n",
       "  (-0.18073653, u'marksman'),\n",
       "  (-0.17289846, u'captain'),\n",
       "  (-0.16785535, u'architect'),\n",
       "  (-0.16702051, u'financier'),\n",
       "  (-0.16313635, u'warrior'),\n",
       "  (-0.1528085, u'major_leaguer'),\n",
       "  (-0.15001449, u'trumpeter'),\n",
       "  (-0.14718857, u'broadcaster'),\n",
       "  (-0.14637242, u'magician'),\n",
       "  (-0.14401685, u'fighter_pilot'),\n",
       "  (-0.13782264, u'boss'),\n",
       "  (-0.13718195, u'industrialist'),\n",
       "  (-0.13684872, u'pundit')],\n",
       " [(0.1971423, u'interior_designer'),\n",
       "  (0.20833443, u'housekeeper'),\n",
       "  (0.21560365, u'stylist'),\n",
       "  (0.22363187, u'bookkeeper'),\n",
       "  (0.23776132, u'maid'),\n",
       "  (0.24125952, u'nun'),\n",
       "  (0.24782585, u'nanny'),\n",
       "  (0.24929325, u'hairdresser'),\n",
       "  (0.24946186, u'paralegal'),\n",
       "  (0.25276455, u'ballerina'),\n",
       "  (0.25718823, u'socialite'),\n",
       "  (0.26647121, u'librarian'),\n",
       "  (0.27317649, u'receptionist'),\n",
       "  (0.27540293, u'waitress'),\n",
       "  (0.28085992, u'nurse'),\n",
       "  (0.30426255, u'registered_nurse'),\n",
       "  (0.30437964, u'homemaker'),\n",
       "  (0.34036586, u'housewife'),\n",
       "  (0.35235125, u'actress'),\n",
       "  (0.35965383, u'businesswoman')])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# profession analysis gender\n",
    "sp = sorted([(E_gnews.v(w).dot(v_gender), w) for w in profession_words])\n",
    "\n",
    "sp[0:20], sp[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Define racial direction\n",
    "We define racial direction based on the common names in different Demographic groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [\"Emily\", \"Aisha\", \"Anne\", \"Keisha\", \"Jill\", \"Tamika\", \"Allison\", \"Lakisha\", \"Laurie\", \"Tanisha\", \"Sarah\",\n",
    "         \"Latoya\", \"Meredith\", \"Kenya\", \"Carrie\", \"Latonya\", \"Kristen\", \"Ebony\", \"Todd\", \"Rasheed\", \"Neil\", \"Tremayne\",\n",
    "         \"Geoffrey\", \"Kareem\", \"Brett\", \"Darnell\", \"Brendan\", \"Tyrone\", \"Greg\", \"Hakim\", \"Matthew\", \"Jamal\", \"Jay\",\n",
    "         \"Leroy\", \"Brad\", \"Jermaine\"]\n",
    "names_group1 = [names[2 * i] for i in range(len(names) // 2)]\n",
    "names_group2 = [names[2 * i + 1] for i in range(len(names) // 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# racial direction\n",
    "vs = [sum(E_gnews.v(w) for w in names) for names in (names_group2, names_group1)]\n",
    "vs = [v / np.linalg.norm(v) for v in vs]\n",
    "\n",
    "v_racial = vs[1] - vs[0]\n",
    "v_racial = v_racial / np.linalg.norm(v_racial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Generating racial biased analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defensemen-cornerbacks\n",
      "hipster-hip_hop\n",
      "punter-cornerback\n",
      "singer_songwriter-rapper\n",
      "defenseman-defensive_tackle\n",
      "pole_vault-triple_jump\n",
      "musicians-artistes\n",
      "musician-artiste\n",
      "catcher-wide_receiver\n",
      "rock_n_roll-reggae\n",
      "kicker-kick_returner\n",
      "tavern-barbershop\n",
      "freestyle_relay-meter_hurdles\n",
      "lefthander-swingman\n",
      "bacon-fried_chicken\n",
      "artists-rappers\n",
      "equipment-equipments\n",
      "hockey-basketball\n",
      "wool-cotton\n",
      "unassisted_goal-layup\n",
      "chocolates-sweets\n",
      "buddy-cousin\n",
      "priest-preacher\n",
      "blue-black\n",
      "medley_relay-meter_dash\n",
      "quirky-funky\n",
      "rabbi-imam\n",
      "grapes-mango\n",
      "telecommunications-telecommunication\n",
      "pitchers-defensive_linemen\n",
      "passages-verses\n",
      "er-o\n",
      "acoustic-soulful\n",
      "punting-punt_returns\n",
      "thefts-armed_robbery\n",
      "bar-nightclub\n",
      "digs-rebounds\n",
      "cellist-saxophonist\n",
      "smarts-quickness\n",
      "puck-halfcourt\n",
      "quarterback-tailback\n",
      "fox-leopard\n",
      "pedophiles-rapists\n",
      "potatoes-flour\n",
      "en-el\n",
      "infrastructure-infrastructural\n",
      "evangelism-gospel\n",
      "fiance-aunt\n",
      "pointers-dunks\n",
      "baseman-defensive_lineman\n",
      "pedophile-rapist\n",
      "joked-smiled\n",
      "beer-soft_drink\n",
      "guitarist-singer\n",
      "election-elections\n",
      "snuck-sneaked\n",
      "mobsters-gangster\n",
      "preventative-preventive\n",
      "wrestling-boxing\n",
      "motorbike-taxi_driver\n",
      "wrestler-boxer\n",
      "aviation-civil_aviation\n",
      "grandfather-uncle\n",
      "walleye-crappie\n",
      "speculates-opined\n",
      "evangelical-preachers\n",
      "wild_pitch-ensuing_kickoff\n",
      "literate-illiterate\n",
      "noted-lamented\n",
      "slams-raps\n",
      "shop-shopkeeper\n",
      "heavyweight-welterweight\n",
      "rider-sprinter\n",
      "hammered-thrashed\n",
      "screwed-messed\n",
      "gymnastics-weightlifting\n",
      "noteworthy-worth_mentioning\n",
      "lobsters-crabs\n",
      "taxpayers-tax_payers\n",
      "co_ops-cooperatives\n",
      "currently-presently\n",
      "carpenter-laborer\n",
      "corn-rice\n",
      "heist-robbery\n",
      "exhilarating-electrifying\n",
      "wife-mother\n",
      "affable-jovial\n",
      "admirable-commendable\n",
      "wetlands-marshes\n",
      "families-relatives\n",
      "cheese-yogurt\n",
      "infielders-safeties\n",
      "groin_strain-hamstring_injury\n",
      "effluent-sewerage\n",
      "pinpointed-identified\n",
      "signal_caller-wideout\n",
      "spooked-scared\n",
      "uninformed-uneducated\n",
      "quarterbacks-wide_receivers\n",
      "lineup-starting_lineup\n"
     ]
    }
   ],
   "source": [
    "# racial analogies\n",
    "a_racial = E.best_analogies_dist_thresh(v_racial)\n",
    "\n",
    "for (a,b,c) in a_racial:\n",
    "    print(a+\"-\"+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Analyzing racial bias in word vectors asscoiated with professions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(-0.31546238, u'artiste'),\n",
       "  (-0.27369621, u'shopkeeper'),\n",
       "  (-0.27285585, u'taxi_driver'),\n",
       "  (-0.24248739, u'cab_driver'),\n",
       "  (-0.23096196, u'preacher'),\n",
       "  (-0.21709052, u'boxer'),\n",
       "  (-0.20973529, u'laborer'),\n",
       "  (-0.2036168, u'barber'),\n",
       "  (-0.19625022, u'cleric'),\n",
       "  (-0.18273093, u'bodyguard'),\n",
       "  (-0.18250422, u'gangster'),\n",
       "  (-0.18162957, u'singer'),\n",
       "  (-0.16877069, u'maid'),\n",
       "  (-0.16871037, u'entertainer'),\n",
       "  (-0.1619755, u'cabbie'),\n",
       "  (-0.15332887, u'housewife'),\n",
       "  (-0.14839581, u'civil_servant'),\n",
       "  (-0.14115781, u'policeman'),\n",
       "  (-0.13648963, u'minister'),\n",
       "  (-0.13296555, u'drug_addict')],\n",
       " [(0.087792605, u'organist'),\n",
       "  (0.090074629, u'philanthropist'),\n",
       "  (0.091352984, u'cinematographer'),\n",
       "  (0.093180187, u'manager'),\n",
       "  (0.093583986, u'investment_banker'),\n",
       "  (0.096878365, u'professor_emeritus'),\n",
       "  (0.097828828, u'curator'),\n",
       "  (0.09864857, u'freelance_writer'),\n",
       "  (0.09917143, u'programmer'),\n",
       "  (0.10142039, u'screenwriter'),\n",
       "  (0.10198854, u'author'),\n",
       "  (0.10438656, u'inventor'),\n",
       "  (0.10677849, u'adventurer'),\n",
       "  (0.10964742, u'naturalist'),\n",
       "  (0.11089919, u'planner'),\n",
       "  (0.1134171, u'historian'),\n",
       "  (0.12044022, u'adjunct_professor'),\n",
       "  (0.13106449, u'director'),\n",
       "  (0.1414099, u'consultant'),\n",
       "  (0.14241588, u'architect')])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# profession analysis racial\n",
    "sp = sorted([(E_gnews.v(w).dot(v_racial), w) for w in profession_words])\n",
    "\n",
    "sp[0:20], sp[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# expansions\n",
    "# Using tools at https://github.com/tolga-b/debiaswe to show debiasing\n",
    "# Analogies using debias embeddings\n",
    "# Analogies using Glove embeddings and cross corpus comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
